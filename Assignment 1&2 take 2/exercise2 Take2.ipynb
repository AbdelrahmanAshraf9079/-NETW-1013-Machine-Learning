{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "# The first two columns contains the exam scores and the third column\n",
    "# contains the label.\n",
    "data = np.loadtxt(os.path.join('Data', 'ex2data1.txt'), delimiter=',')\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X, y = data[:, 0:2], data[:, 2]\n",
    "\n",
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((data.shape[0], 1)), X], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = np.zeros((X.shape[0],5))\n",
    "new_X[:,0:3] = X[:,0:3]\n",
    "new_X[:,3] = X[:,1]**2\n",
    "new_X[:,4] = X[:,2]**3\n",
    "\n",
    "\n",
    "# 60% training set \n",
    "X_train = new_X[0:60,:]\n",
    "y_train = y[0:60]\n",
    "\n",
    "# 20% cross validation set\n",
    "X_cross = new_X[60:80,:]\n",
    "y_cross = y[60:80]\n",
    "\n",
    "# 20% testing set\n",
    "X_test = new_X[80:100,:]\n",
    "y_test = y[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 7.06615096e+01, 9.29271379e+01, 4.99304893e+03,\n",
       "        8.02467928e+05],\n",
       "       [1.00000000e+00, 5.02864961e+01, 4.98045388e+01, 2.52873169e+03,\n",
       "        1.23539764e+05],\n",
       "       [1.00000000e+00, 3.02867108e+01, 4.38949975e+01, 9.17284849e+02,\n",
       "        8.45755998e+04],\n",
       "       [1.00000000e+00, 3.25772002e+01, 9.55985476e+01, 1.06127397e+03,\n",
       "        8.73682995e+05],\n",
       "       [1.00000000e+00, 8.01901808e+01, 4.48216289e+01, 6.43046509e+03,\n",
       "        9.00456853e+04],\n",
       "       [1.00000000e+00, 8.22266616e+01, 4.27198785e+01, 6.76122387e+03,\n",
       "        7.79632666e+04],\n",
       "       [1.00000000e+00, 6.22710137e+01, 6.99544580e+01, 3.87767914e+03,\n",
       "        3.42330967e+05],\n",
       "       [1.00000000e+00, 7.50136584e+01, 3.06032632e+01, 5.62704894e+03,\n",
       "        2.86617837e+04],\n",
       "       [1.00000000e+00, 8.89138964e+01, 6.98037889e+01, 7.90568098e+03,\n",
       "        3.40123774e+05],\n",
       "       [1.00000000e+00, 4.95866772e+01, 5.98089510e+01, 2.45883856e+03,\n",
       "        2.13943234e+05],\n",
       "       [1.00000000e+00, 9.93150088e+01, 6.87754095e+01, 9.86347097e+03,\n",
       "        3.25311603e+05],\n",
       "       [1.00000000e+00, 7.47892530e+01, 4.15734152e+01, 5.59343236e+03,\n",
       "        7.18533646e+04],\n",
       "       [1.00000000e+00, 6.40393204e+01, 7.80316880e+01, 4.10103456e+03,\n",
       "        4.75130605e+05],\n",
       "       [1.00000000e+00, 6.93645888e+01, 9.77186920e+01, 4.81144617e+03,\n",
       "        9.33110196e+05],\n",
       "       [1.00000000e+00, 5.62538175e+01, 3.92614725e+01, 3.16449198e+03,\n",
       "        6.05201160e+04],\n",
       "       [1.00000000e+00, 6.01825994e+01, 8.63085521e+01, 3.62194527e+03,\n",
       "        6.42926746e+05],\n",
       "       [1.00000000e+00, 9.31143888e+01, 3.88006703e+01, 8.67028940e+03,\n",
       "        5.84140995e+04],\n",
       "       [1.00000000e+00, 6.84685218e+01, 8.55943071e+01, 4.68793848e+03,\n",
       "        6.27096883e+05],\n",
       "       [1.00000000e+00, 6.65608945e+01, 4.10920981e+01, 4.43035267e+03,\n",
       "        6.93864947e+04],\n",
       "       [1.00000000e+00, 8.39023937e+01, 5.63080462e+01, 7.03961166e+03,\n",
       "        1.78530070e+05],\n",
       "       [1.00000000e+00, 7.17964621e+01, 7.84535622e+01, 5.15473196e+03,\n",
       "        4.82878650e+05],\n",
       "       [1.00000000e+00, 4.46682617e+01, 6.64500861e+01, 1.99525361e+03,\n",
       "        2.93417927e+05],\n",
       "       [1.00000000e+00, 4.50832775e+01, 5.63163718e+01, 2.03250191e+03,\n",
       "        1.78609273e+05],\n",
       "       [1.00000000e+00, 6.18302060e+01, 5.02561079e+01, 3.82297438e+03,\n",
       "        1.26930665e+05],\n",
       "       [1.00000000e+00, 3.42120610e+01, 4.42095286e+01, 1.17046512e+03,\n",
       "        8.64067464e+04],\n",
       "       [1.00000000e+00, 4.04575510e+01, 9.75351855e+01, 1.63681343e+03,\n",
       "        9.27863183e+05],\n",
       "       [1.00000000e+00, 5.23480040e+01, 6.07695053e+01, 2.74031352e+03,\n",
       "        2.24417697e+05],\n",
       "       [1.00000000e+00, 8.23070534e+01, 7.64819633e+01, 6.77445104e+03,\n",
       "        4.47380534e+05],\n",
       "       [1.00000000e+00, 5.15477203e+01, 4.68562903e+01, 2.65716746e+03,\n",
       "        1.02873545e+05],\n",
       "       [1.00000000e+00, 6.73192575e+01, 6.65893532e+01, 4.53188243e+03,\n",
       "        2.95266645e+05],\n",
       "       [1.00000000e+00, 3.00588224e+01, 4.95929739e+01, 9.03532807e+02,\n",
       "        1.21972087e+05],\n",
       "       [1.00000000e+00, 6.20730638e+01, 9.67688241e+01, 3.85306525e+03,\n",
       "        9.06163138e+05],\n",
       "       [1.00000000e+00, 5.39710521e+01, 8.92073501e+01, 2.91287447e+03,\n",
       "        7.09907750e+05],\n",
       "       [1.00000000e+00, 6.79468555e+01, 4.66785741e+01, 4.61677517e+03,\n",
       "        1.01707445e+05],\n",
       "       [1.00000000e+00, 7.86354243e+01, 9.66474272e+01, 6.18352996e+03,\n",
       "        9.02757056e+05],\n",
       "       [1.00000000e+00, 9.40943311e+01, 7.71591051e+01, 8.85374315e+03,\n",
       "        4.59368854e+05],\n",
       "       [1.00000000e+00, 5.04581598e+01, 7.58098595e+01, 2.54602589e+03,\n",
       "        4.35689482e+05],\n",
       "       [1.00000000e+00, 4.72642691e+01, 8.84758650e+01, 2.23391113e+03,\n",
       "        6.92587185e+05],\n",
       "       [1.00000000e+00, 6.04578857e+01, 7.30949981e+01, 3.65515595e+03,\n",
       "        3.90537712e+05],\n",
       "       [1.00000000e+00, 3.41836400e+01, 7.52377203e+01, 1.16852125e+03,\n",
       "        4.25899259e+05],\n",
       "       [1.00000000e+00, 8.98458067e+01, 4.53582836e+01, 8.07226898e+03,\n",
       "        9.33189485e+04],\n",
       "       [1.00000000e+00, 6.22226758e+01, 5.20609919e+01, 3.87166138e+03,\n",
       "        1.41103347e+05],\n",
       "       [1.00000000e+00, 8.96767758e+01, 6.57993659e+01, 8.04192411e+03,\n",
       "        2.84882076e+05],\n",
       "       [1.00000000e+00, 7.90327361e+01, 7.53443764e+01, 6.24617337e+03,\n",
       "        4.27713077e+05],\n",
       "       [1.00000000e+00, 9.77715993e+01, 8.67278223e+01, 9.55928563e+03,\n",
       "        6.52341977e+05],\n",
       "       [1.00000000e+00, 5.21079797e+01, 6.31276238e+01, 2.71524155e+03,\n",
       "        2.51569697e+05],\n",
       "       [1.00000000e+00, 3.46236596e+01, 7.80246928e+01, 1.19879781e+03,\n",
       "        4.75002836e+05],\n",
       "       [1.00000000e+00, 5.46351056e+01, 5.22138859e+01, 2.98499476e+03,\n",
       "        1.42350189e+05],\n",
       "       [1.00000000e+00, 7.23464942e+01, 9.62275930e+01, 5.23401523e+03,\n",
       "        8.91043420e+05],\n",
       "       [1.00000000e+00, 5.54821611e+01, 3.55707035e+01, 3.07827020e+03,\n",
       "        4.50067199e+04],\n",
       "       [1.00000000e+00, 6.73720275e+01, 4.28384383e+01, 4.53899010e+03,\n",
       "        7.86141803e+04],\n",
       "       [1.00000000e+00, 3.52861128e+01, 4.70205139e+01, 1.24510976e+03,\n",
       "        1.03959005e+05],\n",
       "       [1.00000000e+00, 9.05467141e+01, 4.33906018e+01, 8.19870744e+03,\n",
       "        8.16934093e+04],\n",
       "       [1.00000000e+00, 3.27228330e+01, 4.33071731e+01, 1.07078380e+03,\n",
       "        8.12230898e+04],\n",
       "       [1.00000000e+00, 7.71930349e+01, 7.04582000e+01, 5.95876464e+03,\n",
       "        3.49779725e+05],\n",
       "       [1.00000000e+00, 9.98278578e+01, 7.23692519e+01, 9.96560119e+03,\n",
       "        3.79020107e+05],\n",
       "       [1.00000000e+00, 6.90701441e+01, 5.27404697e+01, 4.77068480e+03,\n",
       "        1.46700631e+05],\n",
       "       [1.00000000e+00, 9.58615551e+01, 3.82252781e+01, 9.18943774e+03,\n",
       "        5.58537015e+04],\n",
       "       [1.00000000e+00, 7.44926924e+01, 8.48451368e+01, 5.54916122e+03,\n",
       "        6.10774453e+05],\n",
       "       [1.00000000e+00, 3.45245139e+01, 6.03963425e+01, 1.19194206e+03,\n",
       "        2.20308837e+05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function given the input z.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        The input to the sigmoid function. This can be a 1-D vector \n",
    "        or a 2-D matrix. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    g : array_like\n",
    "        The computed sigmoid function. g has the same shape as z, since\n",
    "        the sigmoid is computed element-wise on z.\n",
    "        \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the sigmoid of each value of z (z can be a matrix, vector or scalar).\n",
    "    \"\"\"\n",
    "    # convert input to a numpy array\n",
    "    z = np.array(z)\n",
    "    \n",
    "    # You need to return the following variables correctly \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "    # =============================================================\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "\n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    \n",
    "    \n",
    "    # =============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(theta,X,y):\n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done call your `costFunction` using two test cases for  $\\theta$ by executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta found by optimize.minimize: 0.153\n",
      "theta:\n",
      "\t[-30.360, 0.227, 0.254]\n"
     ]
    }
   ],
   "source": [
    "# set options for optimize.minimize\n",
    "options= {'maxiter': 400}\n",
    "\n",
    "# see documention for scipy's optimize.minimize  for description about\n",
    "# the different parameters\n",
    "# The function returns an object `OptimizeResult`\n",
    "# We use truncated Newton algorithm for optimization which is \n",
    "# equivalent to MATLAB's fminunc\n",
    "# See https://stackoverflow.com/questions/18801002/fminunc-alternate-in-numpy\n",
    "\n",
    "\n",
    "\n",
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros(3)\n",
    "\n",
    "\n",
    "\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_theta,\n",
    "                        (X_train[:,0:3], y_train),\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# the fun property of `OptimizeResult` object returns\n",
    "# the value of costFunction at optimized theta\n",
    "cost = res.fun\n",
    "\n",
    "# the optimized theta is in the x property\n",
    "theta = res.x\n",
    "\n",
    "# Print theta to screen\n",
    "print('Cost at theta found by optimize.minimize: {:.3f}'.format(cost))\n",
    "\n",
    "print('theta:')\n",
    "print('\\t[{:.3f}, {:.3f}, {:.3f}]'.format(*theta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression.\n",
    "    Computes the predictions for X using a threshold at 0.5 \n",
    "    (i.e., if sigmoid(theta.T*x) >= 0.5, predict 1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        Parameters for logistic regression. A vecotor of shape (n+1, ).\n",
    "    \n",
    "    X : array_like\n",
    "        The data to use for computing predictions. The rows is the number \n",
    "        of points to compute predictions, and columns is the number of\n",
    "        features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p : array_like\n",
    "        Predictions and 0 or 1 for each row in X. \n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Complete the following code to make predictions using your learned \n",
    "    logistic regression parameters.You should set p to a vector of 0's and 1's    \n",
    "    \"\"\"\n",
    "    m = X.shape[0] # Number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    p = np.round(sigmoid(X.dot(theta.T)))\n",
    "\n",
    "    \n",
    "    # ============================================================\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 80.00 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-30.35962521,   0.22697746,   0.25353898])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute accuracy on our training set\n",
    "p = predict(theta, X_test[:,0:3])\n",
    "print('Train Accuracy: {:.2f} %'.format(np.mean(p == y_test) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p[0:11])\n",
    "print(y_test[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionReg(theta, X, y, lambda_):\n",
    "    \n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ===================== YOUR CODE HERE ======================\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "    \n",
    "    grad = (1 / m) * (h - y).dot(X) \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "    # =============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostReg(theta,X,y,lambda_):\n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(theta))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost is equal =  0.6355786491555002\n",
      "cost is equal =  0.6355840764740229\n",
      "cost is equal =  0.635605883489712\n",
      "cost is equal =  0.6356333215631964\n",
      "cost is equal =  0.6358511810117679\n",
      "cost is equal =  0.6361250430228301\n",
      "cost is equal =  0.6383419016668068\n",
      "cost is equal =  0.6411772833229004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set regularization parameter lambda to 1 (you should vary this)\n",
    "lambda_ = [0,0.01,0.05,0.1,0.5,1,5,10]\n",
    "# set options for optimize.minimize\n",
    "options= {'maxiter': 100}\n",
    "\n",
    "for i in range(len(lambda_)):\n",
    "    \n",
    "    # Initialize fitting parameters\n",
    "    initial_theta = np.zeros(5)\n",
    "    \n",
    "    res = optimize.minimize(costFunctionReg,\n",
    "                            initial_theta,\n",
    "                            (X_train[:,0:5], y_train, lambda_[i]),\n",
    "                            jac=True,\n",
    "                            method='TNC',\n",
    "                            options=options)\n",
    "    print('cost is equal = ',computeCostReg(res.x,X_cross[:,0:5],y_cross,lambda_[i]))\n",
    "\n",
    "\n",
    "# the optimized theta is in the x property of the result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
